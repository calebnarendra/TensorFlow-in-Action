{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 11: Sequence-to-sequence Learning (Part 1)\n",
        "\n",
        "Bab ini membahas dasar-dasar arsitektur *Sequence-to-Sequence* (Seq2Seq), yang menjadi pondasi utama bagi teknologi *Neural Machine Translation* (NMT) atau penerjemahan mesin.\n",
        "\n",
        "---\n",
        "\n",
        "## 11.1 Memahami Data Machine Translation\n",
        "Dalam tugas translasi, model harus memetakan sekuens bahasa sumber ke sekuens bahasa target.\n",
        "* **Dataset**: Kalimat biasanya diurutkan berdasarkan panjangnya untuk efisiensi *padding*.\n",
        "* **Arsitektur Utama**: Terdiri dari **Encoder** yang memproses teks sumber dan **Decoder** yang menghasilkan teks target.\n",
        "* **Context Vector**: Encoder meringkas seluruh informasi dari kalimat sumber ke dalam satu vektor (disebut *context vector* atau *thought vector*) yang kemudian menjadi modal bagi Decoder untuk mulai menerjemahkan.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 11.2 TextVectorization Layer\n",
        "Dalam TensorFlow 2, proses pengolahan teks disederhanakan melalui layer `TextVectorization`.\n",
        "* **Fungsi**: Melakukan standarisasi (menghapus tanda baca), tokenisasi (memecah kalimat), dan pemetaan token menjadi integer ID secara otomatis dalam satu langkah yang terintegrasi dengan model.\n",
        "\n",
        "---\n",
        "\n",
        "## 11.3 Definisi Encoder, Decoder, dan Model Akhir\n",
        "Keduanya biasanya dibangun menggunakan unit berulang seperti **GRU** atau **LSTM**.\n",
        "* **Encoder**: Memproses *sequence source*. *Hidden state* terakhir dari GRU Encoder dijadikan sebagai **Initial State** (kondisi awal) bagi GRU Decoder.\n",
        "* **Decoder**: Menerima target token dan memprediksi token berikutnya berdasarkan informasi dari Encoder dan token-token yang sudah dihasilkan sebelumnya.\n",
        "\n",
        "---\n",
        "\n",
        "## 11.4 Teknik Pelatihan: Teacher Forcing\n",
        "Dalam fase latihan, model menggunakan teknik **Teacher Forcing** untuk mempercepat konvergensi.\n",
        "* **Konsep**: Alih-alih memberikan prediksi Decoder dari langkah sebelumnya sebagai input saat ini, kita langsung memberikan **Target Asli** (kata yang benar) kepada Decoder agar ia tetap pada jalur yang benar selama proses belajar.\n",
        "\n",
        "---\n",
        "\n",
        "## 11.5 Inference Model (Recursive Decoding)\n",
        "Saat model digunakan untuk prediksi nyata (*inference*), target asli tidak tersedia.\n",
        "* **Proses Rekursif**: Decoder beroperasi secara mandiri. Prediksi pada waktu $t$ digunakan kembali sebagai input pada waktu $t+1$.\n",
        "* Proses ini berlanjut terus-menerus hingga model menghasilkan token `<EOS>` (*End of Sequence*).\n",
        "\n",
        "---\n",
        "\n",
        "## 11.6 Metrik Evaluasi: Accuracy & BLEU\n",
        "Evaluasi teks tidak cukup hanya menggunakan akurasi piksel atau label sederhana.\n",
        "* **BLEU (Bilingual Evaluation Understudy)**: Metrik standar untuk tugas Seq2Seq. BLEU menghitung seberapa mirip hasil translasi mesin dengan hasil translasi manusia berdasarkan kesamaan N-gram.\n",
        "* **Implementasi**: Karena TensorFlow menyimpan string dalam format byte, diperlukan konversi menggunakan NumPy sebelum menghitung skor BLEU:\n",
        "  * Gunakan `translations_in_bytes.numpy().astype(np.bytes_)`.\n",
        "  * Konversi array byte tersebut kembali ke format string Python untuk diproses oleh *evaluator*.\n",
        "\n",
        "---\n",
        "\n",
        "## 11.7 Tip Implementasi di Colab\n",
        "Untuk membangun Encoder-Decoder yang kuat, pastikan kamu mengembalikan *state* dari Encoder:\n",
        "\n",
        "```python\n",
        "# Contoh struktur sederhana\n",
        "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "encoder_embedding = tf.keras.layers.Embedding(vocab_size, 256)(encoder_inputs)\n",
        "# return_state=True sangat penting untuk mendapatkan Context Vector\n",
        "encoder_outputs, encoder_state = tf.keras.layers.GRU(512, return_state=True)(encoder_embedding)\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "# Gunakan encoder_state sebagai initial_state decoder\n",
        "decoder_gru = tf.keras.layers.GRU(512, return_sequences=True)(decoder_inputs, initial_state=encoder_state)"
      ],
      "metadata": {
        "id": "LApsuG_P_F8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltcTYJ97--Ds"
      },
      "outputs": [],
      "source": []
    }
  ]
}