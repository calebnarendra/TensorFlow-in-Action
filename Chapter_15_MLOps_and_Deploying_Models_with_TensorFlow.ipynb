{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 15: MLOps and Deploying Models with TensorFlow\n",
        "\n",
        "Bab ini membahas ekosistem MLOps (*Machine Learning Operations*) menggunakan TFX untuk membangun pipeline yang otomatis, mulai dari pemrosesan data, validasi infrastruktur, hingga penyajian model (*serving*).\n",
        "\n",
        "---\n",
        "\n",
        "## 15.1 Membangun Pipeline Data dengan TFX\n",
        "TFX menyediakan kerangka kerja untuk mengotomatisasi seluruh siklus hidup ML.\n",
        "* **Format Data**: Komponen `CsvExampleGen` digunakan untuk membaca file CSV dan mengubahnya menjadi format `tf.Example` (format data standar TensorFlow).\n",
        "* **Environment**: Sangat direkomendasikan menggunakan lingkungan **Linux**.\n",
        "* **Artefak Pipeline**: Setiap tahap dalam TFX menghasilkan \"artefak\" (hasil sementara) yang disimpan dalam *Root Directory* agar proses bisa dilanjutkan jika terjadi kegagalan.\n",
        "* **Logging**: Menggunakan pustaka **Abseil** untuk mencatat log aktivitas sistem secara mendetail.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.2 StatisticsGen & SchemaGen (Automated EDA)\n",
        "Dalam MLOps, analisis data dilakukan secara otomatis untuk menjaga kualitas model:\n",
        "* **StatisticsGen**: Menghasilkan statistik dasar (mean, median, distribusi) dari dataset. Ini membantu mendeteksi anomali data secara cepat.\n",
        "* **SchemaGen**: TFX secara otomatis menyimpulkan \"skema\" data (tipe data, rentang nilai, kategori) setelah statistik berhasil dibuat. Skema ini menjadi acuan validasi untuk data baru di masa depan.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.3 Transformasi Data menjadi Fitur\n",
        "Tahap akhir pipeline pemrosesan data adalah mengubah data mentah menjadi representasi yang dimengerti model:\n",
        "1.  **Dense Floating-point**: Mengubah nilai numerik menjadi tipe *float* standar.\n",
        "2.  **Bucketized**: Mengelompokkan nilai angka ke dalam interval tertentu (misal: usia 0-10, 11-20).\n",
        "3.  **Categorical**: Memetakan nilai teks/kategori ke dalam set nilai yang telah didefinisikan sebelumnya.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.4 Definisi Model & Feature Columns\n",
        "Menggunakan fungsi `_build_keras_model()`, kita menghubungkan data terstruktur ke model Keras.\n",
        "* **tf.feature_column**: Jembatan antara data input (CSV/Tabel) dan Neural Network. Kita mendefinisikan *key* (nama kolom) dan *shape* agar model tahu cara memproses setiap fitur secara spesifik.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.5 SignatureDefs & Penyimpanan Model\n",
        "Agar model bisa diakses melalui web-based API (seperti TensorFlow Serving), model harus disimpan dengan **SignatureDefs**.\n",
        "* **Fungsi**: Mendefinisikan input dan output model secara formal (nama tensor dan tipenya) sehingga sistem luar tahu cara mengirim data ke model tersebut.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.6 TFX Trainer & Validasi Infrastruktur\n",
        "* **Trainer**: Komponen TFX yang melakukan proses pelatihan model secara terpusat.\n",
        "* **InfraValidator**: Tahap krusial sebelum peluncuran. TFX akan membuat kontainer Docker sementara, memasukkan model ke dalamnya, dan mengirimkan permintaan uji coba.\n",
        "* **Tujuan**: Memastikan bahwa model tidak hanya akurat, tetapi juga bisa berjalan (tidak *crash*) di lingkungan produksi yang sebenarnya.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.7 Deployment dengan Docker & TF Serving\n",
        "Produksi model dilakukan dalam lingkungan terisolasi menggunakan **Docker**.\n",
        "1.  **Setup Docker**: Menginstal Docker di Linux untuk membungkus model dan dependensinya.\n",
        "2.  **TensorFlow Serving**: Image Docker resmi dari TF Serving digunakan untuk meluncurkan API.\n",
        "3.  **HTTP Endpoints**: Model dapat diakses melalui URL spesifik (REST API).\n",
        "4.  **Client Request**: Pengguna mengirimkan data (request) ke URL tersebut dan menerima hasil prediksi secara *real-time*.\n",
        "\n",
        "---\n",
        "\n",
        "## 15.8 Tip Instalasi di Colab\n",
        "Untuk mencoba komponen TFX di Colab, kamu perlu menginstal library TFX secara spesifik:\n",
        "\n",
        "```python\n",
        "# Instalasi TFX\n",
        "!pip install tfx\n",
        "\n",
        "import tfx\n",
        "from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, Trainer\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "# Inisialisasi context untuk menjalankan komponen secara interaktif di notebook\n",
        "context = InteractiveContext()"
      ],
      "metadata": {
        "id": "AZZ4JNJIAEM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCEx3wfo__zd"
      },
      "outputs": [],
      "source": []
    }
  ]
}